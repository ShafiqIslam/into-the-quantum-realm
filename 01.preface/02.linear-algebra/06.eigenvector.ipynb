{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the relationship of the form:\n",
    "\n",
    "$$A |v\\rangle \\ = \\ \\lambda |v\\rangle,$$\n",
    "\n",
    "where $A$ is a matrix, and $\\lambda$ is some number. If we are given some matrix $A$, and need to find the vectors $|v\\rangle$ and numbers $\\lambda$ that satisfy this relationship, we call these vectors **eigenvectors**, and their corresponding number multipliers **eigenvalues**. Eigenvectors and eigenvalues have very important physical significance in the context of quantum mechanics, and therefore quantum computation. Given some $A$, we exploit an interesting trick in order to find the set of eigenvectors and corresponding eigenvalues. Let us rearrange our equation as:\n",
    "\n",
    "$$A |v\\rangle \\ - \\ \\lambda |v\\rangle \\ = 0 \\ \\Rightarrow \\ (A \\ - \\ \\lambda \\mathbb{I}) |v\\rangle \\ = \\ 0$$\n",
    "\n",
    "If we multiply both sides of this equation by the inverse matrix $(A \\ - \\ \\lambda \\mathbb{I})^{-1}$, we get $|v\\rangle \\ = \\ 0$. This is an extraneous solution (we don't allow eigenvectors to be the null vector, or else any eigenvalue/matrix combination would satisfy the eigenvector-eigenvalue relationship). Thus, in order to find the allowed eigenvectors and eigenvalues, we have to assume that the matrix $(A \\ - \\ \\lambda \\mathbb{I})$ is **non-invertible**. Recall from earlier that the inverse of a matrix is of the form:\n",
    "\n",
    "$$M^{-1} \\ = \\ \\frac{1}{\\text{det} (M)} \\ F(M),$$\n",
    "\n",
    "where $F(M)$ is some new matrix (the particulars of which do not matter in this context) that depends on $M$. The part of this equation in which we are interested is the inverse of the determinant. If the determinant of the matrix $M$ is $0$, it follows that the inverse is undefined, and thus so is the inverse, making the matrix $M$ non-invertible. We therefore require that:\n",
    "\n",
    "$$\\text{det} (A \\ - \\ \\lambda \\mathbb{I}) \\ = \\ 0$$\n",
    "\n",
    "From this, we can determine $\\lambda$, then we plug each value of $\\lambda$ back into the original equation to get the eigenvectors. Let's do an example, and find the eigenvectors/eigenvalues of the Pauli-Z matrix, $\\sigma_z$. We start with:\n",
    "\n",
    "$$\\text{det} (\\sigma_z \\ - \\ \\lambda \\mathbb{I}) \\ = \\ \\text{det} \\begin{pmatrix} 1 \\ - \\ \\lambda & 0 \\\\ 0 & -1 \\ - \\ \\lambda \\end{pmatrix}  \\ = \\ (-1 \\ - \\ \\lambda)(1 \\ - \\ \\lambda) \\ = \\lambda^2\\ - \\ \\ 1 \\ = \\ 0 \\ \\Rightarrow \\ \\lambda \\ = \\ \\pm 1$$\n",
    "\n",
    "The equation, in terms of $\\lambda$, that results when solving the determinant is called the **characteristic polynomial**. We can then plug each of these values back into the original equation. We'll start with $\\lambda \\ = \\ 1$:\n",
    "\n",
    "$$\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} |v\\rangle \\ = \\ |v\\rangle \\ \\Rightarrow \\ \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\ = \\ \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\ \\Rightarrow \\begin{pmatrix} a \\\\ -b \\end{pmatrix} \\ = \\ \\begin{pmatrix} a \\\\ b \\end{pmatrix}$$\n",
    "\n",
    "$a$ can be any number, and $b$ is $0$; thus, the vector $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ forms a basis for all vectors that satisfy our relationship, and is therefore the eigenvector that corresponds to the eigenvalue of $1$. We do the same thing for $\\lambda \\ = \\ -1$:\n",
    "\n",
    "$$\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} |v\\rangle \\ = \\ -|v\\rangle \\ \\Rightarrow \\ \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\ = \\ \\begin{pmatrix} -a \\\\ -b \\end{pmatrix} \\ \\Rightarrow \\begin{pmatrix} a \\\\ -b \\end{pmatrix} \\ = \\ \\begin{pmatrix} -a \\\\ -b \\end{pmatrix}$$\n",
    "\n",
    "This time, $b$ can be any number, and $a$ is $0$; thus, our basis vector (and our eigenvector corresponding to $-1$) is $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. Notice how the eigenvectors of the Pauli-Z matrix are the quantum computational basis states $|0\\rangle$ and $|1\\rangle$. This is no coincidence. For instance, when we measure a qubit in the $Z$-basis, we are referring to a measurement that collapses the qubit's state into one of the eigenvectors of the Z matrix, either $|0\\rangle$ or $|1\\rangle$.\n",
    "\n",
    "In fact, the following properties are very important in gate model of quantum computation, where we deal with finite dimensional vector spaces:\n",
    "\n",
    "* A Hermitian matrix has linearly independent eigenvectors. The number of these eigenvectors is equal to the dimension of the vector space. In addition, when the corresponding eigenvalues are distinct, the eigenvectors are orthogonal. When the eigenvalues are the same, the eigenvectors are not orthogonal, but they are still linearly independent and can be orthogonalized. Therefore, eigenvectors of a Hermitian matrix form a basis for the vector space.\n",
    "\n",
    "* Since a unitary matrix is a normal matrix, the eigenvectors of a unitary matrix form an orthonormal basis for the vector space.\n",
    "\n",
    "As an important special case, these can be verified for each of the Pauli matrices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
